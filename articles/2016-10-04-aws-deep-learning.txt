package[value="articles"]{}
post[id=aws-deep-learning,date=2016-10-04,description="Installing CUDA, cuDNN, TensorFlow, Theano and Keras on Ubuntu Server 16.04 LTS",Setting up AWS for Deep Learning]{
  This short article will show you how to set up an AWS or Google Cloud instance based on Ubuntu Server 16.04 LTS. I found that most tutorials out there were either outdated or required unnecessary steps. So this is my attempt to provide a simple guide to configuring a minimal instance.

  We are going to install CUDA v8.0 and cuDNN v6.0, as well as TensorFlow, Theano and Keras.

  section[Creating instance and connecting] {
    We will start with creating a new server instance with a GPU attached.

    subsection[AWS] {
      For AWS, we can create the following server from the marketplace:

      quote{Ubuntu 16.04 LTS - Xenial (HVM)}

      After we have downloaded the access key, we need to change its privileges. For convenience, we are also going to store the instance's host and username in the environment variable code{GPU}:

      shell {
        chmod 400 aws-california.pem
        export GPU=ubuntu@ec2-...
      }

      Now, you can easily connect to your instance:

      shell {
        ssh -i aws-california.pem $GPU
      }
    }

    subsection[Google Cloud] {
      For Google Cloud, you need to create a url[compute instance]{https://console.cloud.google.com/compute/instances} and add your public SSH key from code{~/.ssh/id_rsa.pub}. Alternatively, you can connect to the instance directly from the browser.
    }
  }

  section[Installing CUDA and cuDNN] {
    To install CUDA, we will add its official repository, then perform a system upgrade and install it along with the Linux sources and some required kernel modules:

    shell {
      wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb

      sudo dpkg -i cuda-repo-ubuntu1604_8.0.61-1_amd64.deb

      sudo apt-get update
      sudo apt-get upgrade -y
      sudo apt-get install -y cuda linux-source linux-image-extra-virtual
    }

    We need to define the code{CUDA_HOME} environment variable which some frameworks require. Furthermore, we need to amend the user's environment variables for library and binary paths by adding to code{~/.profile}:

    shell {*
      export CUDA_HOME=/usr/local/cuda-8.0
      export LD_LIBRARY_PATH=${CUDA_HOME}/lib64
      export PATH=${CUDA_HOME}/bin:${PATH}
    *}

    Next, we download i{cuDNN v6.0 Runtime Library for Ubuntu16.04 (Deb)} from the url[https://developer.nvidia.com/rdp/cudnn-download]{Nvidia page}.  The file we need is code{libcudnn6_6.0.21-1+cuda8.0_amd64.deb}. We download it locally to the computer and then transfer it using code{scp} to the server:

    shell {
      scp libcudnn6_6.0.21-1+cuda8.0_amd64.deb $GPU:~
    }

    Then, on the instance, the following command will install cuDNN:

    shell {
      sudo dpkg -i libcudnn6_6.0.21-1+cuda8.0_amd64.deb
    }

    Now, we can reboot the machine:

    shell {
      sudo reboot
    }

    As we did a system upgrade earlier and rebooted the machine, code{uname -r} now indicates the current kernel version. We will install the latest Linux headers and finally load the Nvidia kernel module:

    shell {
      sudo apt-get install linux-headers-$(uname -r)
      sudo modprobe nvidia
    }

    If the installation was successful, running code{nvidia-smi} will should show information about the server's GPU.
  }

  section["TensorFlow, Keras and Theano"] {
    We are going to use Python 3's code{pip} to install TensorFlow and other Python libraries. The following command will also install some other dependencies that will be needed in future steps:

    shell {
      sudo apt-get install python3-pip gfortran subversion libblas-dev liblapack-dev libhdf5-dev
    }

    Installing TensorFlow is straightforward:

    shell {
      sudo pip3 install tensorflow-gpu
    }

    Keras has a dependency on Theano, which we are going to install implicitly:

    shell {
      sudo pip3 install keras
    }

    Optionally, you may want to install H5py which is needed to serialise Keras models:

    shell {
      sudo pip3 install h5py
    }

    Finally, we are going to configure Theano for GPU usage and also enable CNMeM for better performance. Please refer to url[http://ankivil.com/making-theano-faster-with-cudnn-and-cnmem-on-windows-10/]{this article} for more information:

    shell {
      echo '[global]
      device = gpu
      floatX = float32
      optimizer = fast_run

      [nvcc]
      fastmath=True

      [lib]
      cnmem = 1.0

      [blas]
      ldflags = -llapack -lblas' > ~/.theanorc
    }
  }

  section[Conclusion] {
    Now, our machine should be fully set up and we can start training some models.

    If you see any potential for improvements, please feel free to send a pull request by clicking "Edit" below.
  }
}
